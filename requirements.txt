# Spark Performance Benchmark - Python Dependencies
# Author: Senior Data Engineer
# Date: 2025-12-08

# Core Spark Dependencies
pyspark>=3.5.0
delta-spark>=3.0.0

# Data Processing & Analysis
pandas>=2.0.0
numpy>=1.24.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0

# Jupyter Notebook Support
jupyter>=1.0.0
notebook>=7.0.0
ipykernel>=6.25.0

# Utilities
python-dateutil>=2.8.0
pyarrow>=14.0.0  # Required for efficient Parquet operations

# Optional: For better performance
# py4j>=0.10.9  # Already included with pyspark
