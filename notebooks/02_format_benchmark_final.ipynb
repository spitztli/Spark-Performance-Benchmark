{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Format Benchmark: CSV vs. Parquet vs. Delta Lake\n",
    "\n",
    "**Objective:** Compare I/O performance and storage efficiency across different file formats.\n",
    "\n",
    "This notebook measures:\n",
    "1. **Read Performance**: Time to load data from each format\n",
    "2. **Storage Efficiency**: Disk space used by each format\n",
    "3. **Query Performance**: Aggregation speed (columnar vs. row-oriented)\n",
    "4. **Filter Pushdown**: Predicate pushdown effectiveness\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src directory to path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent\n",
    "src_dir = project_root / \"src\"\n",
    "sys.path.insert(0, str(src_dir))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Src directory: {src_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import project modules\n",
    "from config import (\n",
    "    get_data_path,\n",
    "    SPARK_APP_NAME,\n",
    "    PLOTS_DIR\n",
    ")\n",
    "from benchmark_utils import BenchmarkTimer, get_directory_size_mb, print_benchmark_summary\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"\u2713 All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session with Delta Lake support\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(f\"{SPARK_APP_NAME} - Format Benchmark\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(f\"\u2713 Spark {spark.version} session initialized\")\n",
    "print(f\"\u2713 App Name: {spark.sparkContext.appName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Size Comparison\n",
    "\n",
    "First, let's compare the disk space used by each format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate storage sizes for all formats\n",
    "storage_data = []\n",
    "\n",
    "for table_name in [\"fact_transactions\", \"dim_accounts\"]:\n",
    "    for fmt in ['csv', 'parquet', 'delta']:\n",
    "        path = get_data_path(fmt, table_name)\n",
    "        if path.exists():\n",
    "            size_mb = get_directory_size_mb(path)\n",
    "            storage_data.append({\n",
    "                'Table': table_name,\n",
    "                'Format': fmt.upper(),\n",
    "                'Size_MB': size_mb\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "storage_df = pd.DataFrame(storage_data)\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*60)\n",
    "print(\"STORAGE SIZE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(storage_df.to_string(index=False))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize storage comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot for fact_transactions\n",
    "sales_data = storage_df[storage_df['Table'] == \"fact_transactions\"]\n",
    "axes[0].bar(sales_data['Format'], sales_data['Size_MB'], color=['#e74c3c', '#3498db', '#2ecc71'])\n",
    "axes[0].set_title('fact_transactions - Storage Size Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Size (MB)', fontsize=12)\n",
    "axes[0].set_xlabel('Format', fontsize=12)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(sales_data['Size_MB']):\n",
    "    axes[0].text(i, v + 5, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot for dim_accounts\n",
    "customer_data = storage_df[storage_df['Table'] == \"dim_accounts\"]\n",
    "axes[1].bar(customer_data['Format'], customer_data['Size_MB'], color=['#e74c3c', '#3498db', '#2ecc71'])\n",
    "axes[1].set_title('dim_accounts - Storage Size Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Size (MB)', fontsize=12)\n",
    "axes[1].set_xlabel('Format', fontsize=12)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(customer_data['Size_MB']):\n",
    "    axes[1].text(i, v + 0.2, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'storage_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\u2713 Plot saved to: {PLOTS_DIR / 'storage_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 1: Full Scan Read Performance\n",
    "\n",
    "Measure how long it takes to read and count all records from each format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CSV read performance\n",
    "with BenchmarkTimer(\n",
    "    \"Read CSV - fact_transactions (Full Scan)\",\n",
    "    description=\"Load and count all records from CSV\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    ") as timer:\n",
    "    csv_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\n",
    "        str(get_data_path(\"csv\", \"fact_transactions\"))\n",
    "    )\n",
    "    count = csv_df.count()\n",
    "    print(f\"Records: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Parquet read performance\n",
    "with BenchmarkTimer(\n",
    "    \"Read Parquet - fact_transactions (Full Scan)\",\n",
    "    description=\"Load and count all records from Parquet\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    ") as timer:\n",
    "    parquet_df = spark.read.parquet(str(get_data_path(\"parquet\", \"fact_transactions\")))\n",
    "    count = parquet_df.count()\n",
    "    print(f\"Records: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Delta read performance\n",
    "with BenchmarkTimer(\n",
    "    \"Read Delta - fact_transactions (Full Scan)\",\n",
    "    description=\"Load and count all records from Delta\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    ") as timer:\n",
    "    delta_df = spark.read.format(\"delta\").load(str(get_data_path(\"delta\", \"fact_transactions\")))\n",
    "    count = delta_df.count()\n",
    "    print(f\"Records: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 2: Columnar Aggregation Performance\n",
    "\n",
    "Test aggregation performance to highlight the advantage of columnar formats.\n",
    "We'll aggregate sales by product category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV aggregation\n",
    "with BenchmarkTimer(\n",
    "    \"CSV - Aggregation by Category\",\n",
    "    description=\"GroupBy transaction_type and sum amount\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    csv_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\n",
    "        str(get_data_path(\"csv\", \"fact_transactions\"))\n",
    "    )\n",
    "    result = csv_df.groupBy(\"transaction_type\").agg(\n",
    "        F.sum(\"amount\").alias(\"total_amount\"),\n",
    "        F.count(\"*\").alias(\"num_transactions\")\n",
    "    ).orderBy(\"transaction_type\").collect()\n",
    "    print(f\"Categories: {len(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet aggregation\n",
    "with BenchmarkTimer(\n",
    "    \"Parquet - Aggregation by Category\",\n",
    "    description=\"GroupBy transaction_type and sum amount\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    parquet_df = spark.read.parquet(str(get_data_path(\"parquet\", \"fact_transactions\")))\n",
    "    result = parquet_df.groupBy(\"transaction_type\").agg(\n",
    "        F.sum(\"amount\").alias(\"total_amount\"),\n",
    "        F.count(\"*\").alias(\"num_transactions\")\n",
    "    ).orderBy(\"transaction_type\").collect()\n",
    "    print(f\"Categories: {len(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta aggregation\n",
    "with BenchmarkTimer(\n",
    "    \"Delta - Aggregation by Category\",\n",
    "    description=\"GroupBy transaction_type and sum amount\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    delta_df = spark.read.format(\"delta\").load(str(get_data_path(\"delta\", \"fact_transactions\")))\n",
    "    result = delta_df.groupBy(\"transaction_type\").agg(\n",
    "        F.sum(\"amount\").alias(\"total_amount\"),\n",
    "        F.count(\"*\").alias(\"num_transactions\")\n",
    "    ).orderBy(\"transaction_type\").collect()\n",
    "    print(f\"Categories: {len(result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 3: Filter Pushdown (Predicate Pushdown)\n",
    "\n",
    "Test how well each format supports predicate pushdown optimization.\n",
    "We'll filter for specific product categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV with filter\n",
    "with BenchmarkTimer(\n",
    "    \"CSV - Filter Electronics Category\",\n",
    "    description=\"Filter transaction_type = 'Electronics' and count\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    csv_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\n",
    "        str(get_data_path(\"csv\", \"fact_transactions\"))\n",
    "    )\n",
    "    filtered = csv_df.filter(F.col(\"transaction_type\") == \"Electronics\")\n",
    "    count = filtered.count()\n",
    "    print(f\"Filtered records: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet with filter (should benefit from predicate pushdown)\n",
    "with BenchmarkTimer(\n",
    "    \"Parquet - Filter Electronics Category\",\n",
    "    description=\"Filter transaction_type = 'Electronics' and count\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    parquet_df = spark.read.parquet(str(get_data_path(\"parquet\", \"fact_transactions\")))\n",
    "    filtered = parquet_df.filter(F.col(\"transaction_type\") == \"Electronics\")\n",
    "    count = filtered.count()\n",
    "    print(f\"Filtered records: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta with filter (should benefit from data skipping)\n",
    "with BenchmarkTimer(\n",
    "    \"Delta - Filter Electronics Category\",\n",
    "    description=\"Filter transaction_type = 'Electronics' and count\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    delta_df = spark.read.format(\"delta\").load(str(get_data_path(\"delta\", \"fact_transactions\")))\n",
    "    filtered = delta_df.filter(F.col(\"transaction_type\") == \"Electronics\")\n",
    "    count = filtered.count()\n",
    "    print(f\"Filtered records: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark 4: Selective Column Read\n",
    "\n",
    "Test columnar format advantage when reading only specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV - Read only 2 columns\n",
    "with BenchmarkTimer(\n",
    "    \"CSV - Select 2 Columns\",\n",
    "    description=\"Read only customer_id and amount columns\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    csv_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\n",
    "        str(get_data_path(\"csv\", \"fact_transactions\"))\n",
    "    )\n",
    "    result = csv_df.select(\"account_orig\", \"amount\").count()\n",
    "    print(f\"Records: {result:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet - Read only 2 columns (should be much faster)\n",
    "with BenchmarkTimer(\n",
    "    \"Parquet - Select 2 Columns\",\n",
    "    description=\"Read only customer_id and amount columns\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    parquet_df = spark.read.parquet(str(get_data_path(\"parquet\", \"fact_transactions\")))\n",
    "    result = parquet_df.select(\"account_orig\", \"amount\").count()\n",
    "    print(f\"Records: {result:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta - Read only 2 columns (should also benefit from columnar format)\n",
    "with BenchmarkTimer(\n",
    "    \"Delta - Select 2 Columns\",\n",
    "    description=\"Read only customer_id and amount columns\",\n",
    "    spark=spark,\n",
    "    clear_cache=True\n",
    "):\n",
    "    delta_df = spark.read.format(\"delta\").load(str(get_data_path(\"delta\", \"fact_transactions\")))\n",
    "    result = delta_df.select(\"account_orig\", \"amount\").count()\n",
    "    print(f\"Records: {result:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This cell reads historical benchmark results from previous runs\n",
    "# On first run, you'll see 'No benchmark results found' - this is normal!\n",
    "# The benchmarks are still being executed and timed in the cells above.\n",
    "\n",
    "# Analyze benchmark results from log\n",
    "import csv\n",
    "import pandas as pd\n",
    "from config import BENCHMARK_LOG_FILE\n",
    "\n",
    "benchmark_results = []\n",
    "\n",
    "if BENCHMARK_LOG_FILE.exists():\n",
    "    with open(BENCHMARK_LOG_FILE, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            # Check if required keys exist\n",
    "            test_name = row.get('test_name', '')\n",
    "            status = row.get('status', '')\n",
    "            \n",
    "            if 'fact_transactions' in test_name and status == 'SUCCESS':\n",
    "                benchmark_results.append(row)\n",
    "    \n",
    "    if benchmark_results:\n",
    "        # Create DataFrame for analysis\n",
    "        results_df = pd.DataFrame(benchmark_results)\n",
    "        results_df['duration_seconds'] = pd.to_numeric(results_df['duration_seconds'], errors='coerce')\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"BENCHMARK RESULTS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(results_df[['test_name', 'duration_seconds', 'status']].to_string(index=False))\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"No benchmark results found for fact_transactions\")\n",
    "else:\n",
    "    print(f\"Benchmark log file not found: {BENCHMARK_LOG_FILE}\")\n",
    "    print(\"Results have been timed but not logged to file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this analysis if we have benchmark results\n",
    "if 'results_df' in locals() and not results_df.empty:\n",
    "    # Create performance comparison visualization\n",
    "    # Extract format from test name and categorize benchmarks\n",
    "    def extract_format_and_test(test_name):\n",
    "        if 'CSV' in test_name:\n",
    "            fmt = 'CSV'\n",
    "        elif 'Parquet' in test_name:\n",
    "            fmt = 'Parquet'\n",
    "        elif 'Delta' in test_name:\n",
    "            fmt = 'Delta'\n",
    "        else:\n",
    "            fmt = 'Unknown'\n",
    "        \n",
    "        if 'Full Scan' in test_name:\n",
    "            test = 'Full Scan'\n",
    "        elif 'Aggregation' in test_name:\n",
    "            test = 'Aggregation'\n",
    "        elif 'Filter' in test_name:\n",
    "            test = 'Filter'\n",
    "        elif 'Select 2 Columns' in test_name:\n",
    "            test = 'Column Select'\n",
    "        else:\n",
    "            test = 'Other'\n",
    "        \n",
    "        return fmt, test\n",
    "    \n",
    "    # Only use the most recent format benchmarks (last 12 entries)\n",
    "    recent_results = results_df.tail(12).copy()\n",
    "    recent_results[['format', 'test_type']] = recent_results['test_name'].apply(\n",
    "        lambda x: pd.Series(extract_format_and_test(x))\n",
    "    )\n",
    "    \n",
    "    # Filter for comparison tests\n",
    "    comparison_tests = recent_results[recent_results['test_type'].isin(['Full Scan', 'Aggregation', 'Filter', 'Column Select'])]\n",
    "    \n",
    "    if len(comparison_tests) > 0:\n",
    "        # Create grouped bar chart\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        \n",
    "        # Pivot data for grouped bars\n",
    "        pivot_data = comparison_tests.pivot_table(\n",
    "            index='test_type',\n",
    "            columns='format',\n",
    "            values='duration_seconds',\n",
    "            aggfunc='first'\n",
    "        )\n",
    "        \n",
    "        # Plot grouped bars\n",
    "        pivot_data.plot(kind='bar', ax=ax, color=['#e74c3c', '#3498db', '#2ecc71'], width=0.7)\n",
    "        \n",
    "        ax.set_title('Format Performance Comparison - fact_transactions', fontsize=16, fontweight='bold')\n",
    "        ax.set_ylabel('Duration (seconds)', fontsize=12)\n",
    "        ax.set_xlabel('Benchmark Type', fontsize=12)\n",
    "        ax.legend(title='Format', fontsize=11)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(PLOTS_DIR / 'format_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\u2713 Plot saved to: {PLOTS_DIR / 'format_performance_comparison.png'}\")\n",
    "    else:\n",
    "        print(\"\u26a0 Not enough data for visualization\")\n",
    "else:\n",
    "    print('Skipping visualization - no benchmark results available yet.')\n",
    "    print('Run the benchmark cells above first to generate data.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive benchmark summary\n",
    "try:\n",
    "    print_benchmark_summary()\n",
    "except Exception as e:\n",
    "    print(f'Note: Could not load benchmark summary: {e}')\n",
    "    print('This is normal on first run - results are still being logged.')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "Expected Performance Characteristics:\n",
    "\n",
    "1. STORAGE EFFICIENCY:\n",
    "   - Parquet/Delta: 50-70% smaller than CSV due to compression\n",
    "   - Columnar format benefits: Better compression ratios\n",
    "\n",
    "2. FULL SCAN PERFORMANCE:\n",
    "   - CSV: Slowest (row-oriented, no compression)\n",
    "   - Parquet/Delta: Faster (columnar, compressed)\n",
    "\n",
    "3. AGGREGATION PERFORMANCE:\n",
    "   - Columnar formats excel: Only read required columns\n",
    "   - CSV must read all columns regardless\n",
    "\n",
    "4. FILTER PUSHDOWN:\n",
    "   - Parquet/Delta: Support predicate pushdown\n",
    "   - Delta: Additional data skipping with statistics\n",
    "\n",
    "5. COLUMN PROJECTION:\n",
    "   - Parquet/Delta: Huge advantage when selecting few columns\n",
    "   - CSV: Must read entire row even for single column\n",
    "\"\"\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n\u2713 Format benchmark completed!\")\n",
    "print(\"Next step: Run notebook 03_join_optimization.ipynb\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}